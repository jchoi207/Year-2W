# Lecture 13-2 

## Sums of Errors
- $$S_{xx} =  \sum_{i=1}^{n} (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 = \left( \sum_{i=1}^{n} x_i^2 \right) - n(\bar{x})^2$$

- $$S_{yy} = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 = \left( \sum_{i=1}^{n} y_i^2 \right) - n(\bar{y})^2$$

- $$S_{xy} =  \sum_{i=1}^n (y_i - \bar{y})(x_i - \bar{x}) = \left( \sum_{i=1}^{n} x_iy_i \right) - n\bar{x}\bar{y}$$



## Sum of Errors and Unbiased Estimators for $\sigma^2$ 
- The sum of squared errors (SSE) is given by: 
$$ SSE = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - b_0 - b_1x_i)^2 = \ldots = S_{yy} - b_1S_{xy}$$
- Where $b_1 = \frac{S_{xy}}{S_{xx}}$. 
- An unbiased estimate of $\sigma^2$ is: 
$$ s^2 = \frac{SSE}{n-2} = \frac{S_{yy} - b_1S_{xy}}{n-2}$$



## Confidence Interval for the Slope 
- We use the a t-statistic for $b_1$: 
$$T = \frac{B_1 - \beta_1}{s/\sqrt{S_{xx}}}$$
-  $n-2$ degrees of freedom 
- Used to find a $100(1-\alpha)\%$ confidence interval for $\beta_1$ given some regression line $\mu_y = \beta_0 + \beta_1x$ is:
$$b_1 - t_{\alpha/2} \frac{s}{\sqrt{S_{xx}}} \leq \beta_1 \leq b_1 + t_{\alpha/2} \frac{s}{\sqrt{S_{xx}}} = \frac{B_1 - \beta_1}{\sqrt{\frac{s_yy - b_1 s_{xy}}{(n-2) s_{xx}}}}$$


## Hypothesis Testing for the Slope
- Null hypothesis: $H_0: \beta_1 = \beta_{1_0}$
- Alternative hypothesis (two-sided): $H_1: \beta_1 \neq \beta_{1_0}$
- Alternative hypothesis (one-sided): $H_1: \beta_1 > \beta_{1_0}$ or $H_1: \beta_1 < \beta_{1_0}$


### Example 1 
- Using the estimated value $b_1 = 0.903643$ test the hypothesis that $\beta_1 = 1.0$ against the alternative that $\beta_1 < 1.0$ at the significance level of 0.05. 
- $\sum_{i=1}^{33} y_i^2 = 41998$

**Solution**
- We have a one sided test. 
- $H_0: \beta_1 = 1.0$ and $H_1: \beta_1 < 1.0$

$$t = \frac{\beta_1 - \beta_{1_0}}{s/\sqrt{S_{xx}}} = \frac{0.903643 - 1.0}{3.2295 / \sqrt{4152.18} }= -1.92$$ 

- With $n-2 = 31$ dof, $P = 0.03$.
- Thus, the t-value is significant at the 0.03 level,suggesting sttrong evidence that $\beta_1 < 1.0$, so we reject the null

## Confidence Interval for the Incercept: 
- We use the t-statistic for $b_0$: 
$$ T = \frac{B_0 - \beta_0}{s\sqrt{\frac{1}{n} + \frac{\bar{x}^2}{S_{xx}}}}$$
- $n-2$ degrees of freedom
- Used to find a $100(1-\alpha)\%$ confidence interval for $\beta_0$ given some regression line $\mu_y = \beta_0 + \beta_1x$ is:
$$b_0 - t_{\alpha/2} \frac{s}{\sqrt{n S_{xx}}} \sqrt{\sum_{i=1}^{n}x_i^2} \leq \beta_0 \leq b_0 + t_{\alpha/2} \frac{s}{\sqrt{n S_{xx}}} \sqrt{\sum_{i=1}^{n}x_i^2}$$

## Hypothesis Testing for the Intercept
- Null hypothesis: $H_0: \beta_0 = \beta_{0_0}$
- Alternative hypothesis (two-sided): $H_1: \beta_0 \neq \beta_{0_0}$
- Alternative hypothesis (one-sided): $H_1: \beta_0 > \beta_{0_0}$ or $H_1: \beta_0 < \beta_{0_0}$
- The test statistic is:
$$t = \frac{b_0 - \beta_{0_0}}{s\sqrt{\frac{\sum_{i=1}^{n} x_i^2} {n S_{xx}}}}$$



### Example 2 
- Use $b_0 = 3.829633$ to test the hypothesis that $\beta_0 =0.0$ against the alternative that $\beta_0 \neq 0 $ at the significance level of 0.05.

**Solution**
- $$t = \frac{3.829633}- 0.0{3.2295 \sqrt{\frac{41086}{33 (4152.18)}}} = 2.17$$ 
- With 31 dof, we have that $P = 0.038$. 
- Look for t-statistic w/ 31 dof and t = 2.17, which gives a probability of around 0.038 
    - $P(T > 2.17) = 0.19$
- Thus, the t-value is less than 0.05, so we reject the null hypothesis.

## Coefficent of Determination
- Denoted as $R^2$ measures the proportional of variability in the response variable
$$R^2 = 1 - \frac{SSE}{SST}$$
- Where SSE is the error sum of squares and SST is the total correct sume of squares
    - $$SSE= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$
    - $$SST = \sum_{i=1}^{n} (y_i - \bar{y})^2$$
- $R^2$  represents how well the regression line approximates the real data 


### EXAM:
- Not gollowing the same format
- 2 cheat sheets 
- everything is equal weighted 
- no direct proofs 
